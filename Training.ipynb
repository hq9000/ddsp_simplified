{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, yaml\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "#from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from encoders import SupervisedEncoder\n",
    "from decoders import DecoderWithoutLatent, DecoderWithLatent\n",
    "from models import SupervisedAutoencoder, UnsupervisedAutoencoder\n",
    "from losses import SpectralLoss, MultiLoss\n",
    "from preprocessing import F0LoudnessPreprocessor, MidiF0LoudnessPreprocessor\n",
    "from dataloader import make_supervised_dataset\n",
    "from callbacks import CustomWandbCallback, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('configs/exp.yaml') as file:\n",
    "    config = dict(yaml.load(file, Loader=yaml.FullLoader))\n",
    "    data, train = config['data'], config['training']\n",
    "    model_config, optim = config['model'], config['optimizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_set, validation_set, _ = make_supervised_dataset(data['path'],\n",
    "                                                model_config['encoder'],\n",
    "                                                train['batch_size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised DDSP\n",
    "\n",
    "### TO DO\n",
    "\n",
    "with logmag\n",
    "without logmag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_timesteps = 250\n",
    "decoder_timesteps = 1000\n",
    "\n",
    "preprocessor = F0LoudnessPreprocessor(timesteps=preprocessing_timesteps)\n",
    "\n",
    "# Without Latent\n",
    "encoder = None\n",
    "decoder = DecoderWithoutLatent(timesteps=decoder_timesteps)\n",
    "\n",
    "# With Latent\n",
    "#encoder = SupervisedEncoder()\n",
    "#decoder = DecoderWithLatent(timesteps=decoder_timesteps)\n",
    "\n",
    "# Choose a loss\n",
    "loss = SpectralLoss(logmag_weight=1.0)\n",
    "#loss = MultiLoss()\n",
    "\n",
    "tracker_names = ['spec_loss'] if loss.name=='spectral_loss' else ['spec_loss', 'perc_loss', 'total_loss']\n",
    "\n",
    "model = SupervisedAutoencoder(preprocessor=preprocessor,\n",
    "                            encoder=encoder,\n",
    "                            decoder=decoder,\n",
    "                            loss_fn=loss,\n",
    "                            tracker_names=tracker_names,\n",
    "                            add_reverb=True)\n",
    "                                \n",
    "adam = Adam(learning_rate=ExponentialDecay(1e-3, decay_steps=10000, decay_rate=0.98))\n",
    "\n",
    "model_dir = \"model_checkpoints/yeah_{}\".format(config['run_name'])\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "#callbacks = [ModelCheckpoint(filepath=os.path.join(model_dir, 'model.ckpt'),\n",
    "#                              monitor='val_spec_loss' if loss.name=='spectral_loss' else 'val_total_loss',\n",
    "#                              save_best_only=True)]\n",
    "\n",
    "callbacks = [ModelCheckpoint(model_dir,\n",
    "               monitor='val_spec_loss' if loss.name=='spectral_loss' else 'val_total_loss')]\n",
    "\n",
    "#csv_logger = tf.keras.callbacks.CSVLogger(\"logs/{}.csv\".format(RUN_NAME), separator=\",\", append=False)\n",
    "#callbacks = [ModelCheckpoint(model, RUN_NAME), csv_logger]\n",
    "#callbacks.append(CustomWandbCallback(RUN_NAME)) # uncomment for WANDB\n",
    "\n",
    "model.compile(adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_set, validation_data=validation_set, epochs=10, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_timesteps = 250\n",
    "decoder_timesteps = 1000\n",
    "\n",
    "preprocessor = F0LoudnessPreprocessor(timesteps=preprocessing_timesteps)\n",
    "\n",
    "# Without Latent\n",
    "encoder = None\n",
    "decoder = DecoderWithoutLatent(timesteps=decoder_timesteps)\n",
    "\n",
    "# With Latent\n",
    "#encoder = SupervisedEncoder()\n",
    "#decoder = DecoderWithLatent(timesteps=decoder_timesteps)\n",
    "\n",
    "# Choose a loss\n",
    "loss = SpectralLoss(logmag_weight=1.0)\n",
    "#loss = MultiLoss()\n",
    "\n",
    "tracker_names = ['spec_loss'] if loss.name=='spectral_loss' else ['spec_loss', 'perc_loss', 'total_loss']\n",
    "\n",
    "model = SupervisedAutoencoder(preprocessor=preprocessor,\n",
    "                            encoder=encoder,\n",
    "                            decoder=decoder,\n",
    "                            loss_fn=loss,\n",
    "                            tracker_names=tracker_names,\n",
    "                            add_reverb=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised DDSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import f0_midi_scaled_L1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 250\n",
    "\n",
    "encoder_z = Encoder_z(timesteps=timesteps)\n",
    "encoder_f0 = Encoder_f(timesteps=timesteps)\n",
    "\n",
    "decoder = DecoderWithLatent()\n",
    "\n",
    "preprocessor = MidiF0LoudnessPreprocessor(timesteps=timesteps)\n",
    "\n",
    "#loss = SpectralLoss(logmag_weight=1.0)\n",
    "loss = MultiLoss(logmag_weight=1.0, perceptual_loss_weight=38)\n",
    "\n",
    "metric_fns = {\"F0_recons_L1\": f0_midi_scaled_L1_loss}\n",
    "\n",
    "model = UnsupervisedAutoencoder(preprocessor=preprocessor,\n",
    "                                encoder_f0=encoder_f0,\n",
    "                                encoder_z=encoder_z,\n",
    "                                decoder=decoder,\n",
    "                                loss_fn=loss,\n",
    "                                tracker_names=[\"total_loss\", \"spec_loss\", \"perc_loss\",\"F0_recons_L1\"],\n",
    "                                metric_fns=metric_fns)\n",
    "\n",
    "decay = ExponentialDecay(1e-3, decay_steps=10000, decay_rate=0.98)\n",
    "adam = Adam(learning_rate=decay)\n",
    "\n",
    "csv_logger = tf.keras.callbacks.CSVLogger(\"logs/{}.csv\".format(RUN_NAME), separator=\",\", append=False)\n",
    "\n",
    "callbacks = [ModelCheckpoint(model, RUN_NAME), csv_logger, CustomWandbCallback(RUN_NAME)]\n",
    "\n",
    "model.compile(adam, metrics = [f0_midi_scaled_L1_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_set, \n",
    "                    validation_data=validation_set,\n",
    "                    callbacks=callbacks, \n",
    "                    epochs=1000,\n",
    "                    steps_per_epoch=train_set.my_len,\n",
    "                    validation_steps=validation_set.my_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "\n",
    "supervised data\\\n",
    "supervised model\n",
    "\n",
    "interpolation/extrapolation (optional) \\\n",
    "test metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k_filters = [128]*2 + [256]*3 + [512]*4 + [1024]*3\n",
    "#s_freqs = [1,1,2]*2 + [1,1,1,2] + [1,1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load(\"SupervisedViolinModel/300/model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsp_utils.spectral_ops import compute_mfcc, compute_logmel, compute_loudness, compute_f0\n",
    "def calculate_recons_f0_error(dataset):\n",
    "    it = iter(dataset)\n",
    "    preds,truth = [],[]\n",
    "    for batch in it:\n",
    "        pred = model(batch)\n",
    "        preds.append(pred[\"audio_synth\"].numpy())\n",
    "        truth.append(pred[\"inputs\"][\"f0_hz\"].numpy())\n",
    "    pred_f0 = [compute_f0(p[0], 16000, 250, viterbi=True)[0] for p in preds]\n",
    "    error = np.mean(np.abs(np.array(truth)[:,0,:,0]-np.array(pred_f0)))\n",
    "    hz_to_midi = core.hz_to_midi\n",
    "    F0_RANGE = spectral_ops.F0_RANGE\n",
    "    return hz_to_midi(error)/F0_RANGE\n",
    "calculate_recons_f0_error(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = {'model': {'input': 3, 'output': 4}, 'decoder': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('y.yaml', 'w') as f:\n",
    "    yaml.dump(config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('x.yaml') as file:\n",
    "    config = dict(yaml.load(file, Loader=yaml.FullLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.dirname('lol/audio_clips/Violin.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'run_name': 'lol',\n",
    "         'wandb': {}, #leave empty for not using 'project_name': 'supervised'\n",
    "         'data': {'path': \"audio_clips/Violin\",\n",
    "                 'sample_rate': 16000,\n",
    "                 'preprocessing_time': 250,\n",
    "                  'sample_rate' = 16000},\n",
    "         'model': {'encoder': False, # use an encoder or not\n",
    "                   'decoder_time': 1000,\n",
    "                   'reverb': True,\n",
    "                   'loss': 'spectral',\n",
    "                   'path': 'here'},\n",
    "         'optimizer': {'name': 'Adam', # just for reference\n",
    "                        'lr': 1e-3,\n",
    "                        'decay_steps': 10000,\n",
    "                        'decay_rate': 0.98},\n",
    "         'training': {'batch_size':32,\n",
    "                     'epochs': 1000}\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config['wandb']:\n",
    "    print('lol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
