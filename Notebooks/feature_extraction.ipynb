{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys\n",
    "import glob, pickle, yaml\n",
    "\n",
    "sys.path.append('/scratch/users/hbalim15/ddsp')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal as signal\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "from encoders import SupervisedEncoder\n",
    "from decoders import DecoderWithoutLatent, DecoderWithLatent\n",
    "from models import SupervisedAutoencoder, UnsupervisedAutoencoder\n",
    "from losses import SpectralLoss, MultiLoss\n",
    "from preprocessing import F0LoudnessPreprocessor, MidiF0LoudnessPreprocessor\n",
    "from dataloader import make_supervised_dataset\n",
    "from callbacks import CustomWandbCallback, ModelCheckpoint\n",
    "from train_supervised import make_supervised_model\n",
    "from timbre_transfer import transfer_timbre_from_filepath\n",
    "\n",
    "from feature_extraction import *\n",
    "import utilities\n",
    "\n",
    "\n",
    "def print_plot_play(x, Fs=16000, text='', normalize=False):\n",
    "    import IPython.display as ipd\n",
    "    print('%s\\n' % (text))\n",
    "    print('Fs = %d, x.shape = %s, x.dtype = %s' % (Fs, x.shape, x.dtype))\n",
    "    plt.figure(figsize=(8, 2))\n",
    "    plt.plot(x, color='gray')\n",
    "    plt.xlim([0, x.shape[0]])\n",
    "    plt.xlabel('Time (samples)')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    ipd.display(ipd.Audio(data=x, rate=Fs, normalize=normalize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = '/kuacc/users/hbalim15/ddsp/wandb/run-20210816_095238-elee4v03/files/exp3/exp3.yml'\n",
    "\n",
    "with open(config_path) as file:\n",
    "    config = dict(yaml.load(file, Loader=yaml.FullLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_title = \"singing.mp3\" \n",
    "input_path = os.path.join(\"../audio_clips\", '{}'.format(input_title))\n",
    "Fs = 16000\n",
    "track = utilities.load_track(input_path,\n",
    "                             sample_rate=Fs,\n",
    "                            pitch_shift=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = process_track(track, mfcc=True, audio_length=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in features.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['loudness_db']+3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = frame_generator(track, 4*Fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = extract_features_from_frames(frames, mfcc=True, log_mel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in features.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = feature_extractor(frames[0], mfcc=True, log_mel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['audio'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['f0_hz'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['loudness_db'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['mfcc'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['log_mel'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, _ = make_supervised_dataset('../audio_clips/Violin_short', mfcc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in batch.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in batch.items():\n",
    "    print(k, v.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
